{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Gradient_Descent.ipynb","provenance":[],"authorship_tag":"ABX9TyOaXZPqKpI8cLcyaj5suSsU"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"dLuncWjhwowi","executionInfo":{"status":"ok","timestamp":1639058012265,"user_tz":-330,"elapsed":435,"user":{"displayName":"Soham Shinde","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjp2-AFC4Bku5hWXXa7gtTdvsjnBYU2nS7JI5VB=s64","userId":"11067531772103742328"}}},"source":["import numpy as np\n","def gradient_descent(x,y):\n","  m_curr=b_curr=0\n","  iterations = 1000\n","  n= len(x)\n","  learning_rate=0.001\n","\n","  for i in range (iterations):\n","    y_predicted = m_curr * x + b_curr\n","    cost= (1/n) * ([val**2 for val in (y-y_predicted)])\n","    md= -(2/n) * sum(x*(y-y_predicted))\n","    bd = -(2/n) * sum(y-y_predicted)\n","    m_curr = m_curr - learning_rate * md\n","    b_curr = b_curr - learning_rate * bd\n","    print(\"m{} , b{} , iterations{}\".format(m_curr, b_curr , i))\n","\n","    x = np.array([1,2,3,4,5])\n","    y = np.array([5,7,9,11,13])\n","\n","  gradient_descent(x,y)  \n"],"execution_count":5,"outputs":[]}]}